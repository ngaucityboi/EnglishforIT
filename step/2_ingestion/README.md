# ğŸ“¥ GIAI ÄOáº N 2: INGESTION PIPELINE

## ğŸ“Œ Tá»•ng quan

Há»‡ thá»‘ng ingestion chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u vÄƒn báº£n luáº­t Ä‘Ã£ lÃ m sáº¡ch thÃ nh vector database FAISS Ä‘á»ƒ phá»¥c vá»¥ tÃ¬m kiáº¿m ngá»¯ nghÄ©a trong RAG system.

## ğŸ¯ Má»¥c tiÃªu

- Äá»c dá»¯ liá»‡u tá»« 4 file JSON Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch (212 Ä‘iá»u luáº­t)
- Chuyá»ƒn Ä‘á»•i thÃ nh LangChain Document objects vá»›i metadata Ä‘áº§y Ä‘á»§
- Táº¡o vector embeddings báº±ng model Ä‘a ngÃ´n ngá»¯ (384 dimensions)
- LÆ°u trá»¯ vÃ o FAISS index Ä‘á»ƒ retrieval nhanh (<100ms)
- Äáº£m báº£o metadata chÃ­nh xÃ¡c 100% (Ä‘Ã£ fix duplicate IDs vÃ  citations)

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
2_ingestion/
â”œâ”€â”€ ingestion_pipeline.py      # Pipeline chÃ­nh - xá»­ lÃ½ tá»« JSON â†’ FAISS
â”œâ”€â”€ demo_retrieval.py          # Script demo tÃ¬m kiáº¿m semantic search
â”œâ”€â”€ README.md                  # TÃ i liá»‡u nÃ y
â””â”€â”€ output/                    # Output directory (tá»± Ä‘á»™ng táº¡o)
    â”œâ”€â”€ law_documents_index_config.json  # Metadata cáº¥u hÃ¬nh (317 bytes)
    â””â”€â”€ law_documents_index/
        â”œâ”€â”€ index.faiss        # FAISS vector index (325 KB)
        â””â”€â”€ index.pkl          # Document metadata & docstore (441 KB)
```

**LÆ°u Ã½**: Dependencies Ä‘Æ°á»£c quáº£n lÃ½ táº­p trung táº¡i [requirements.txt](../../requirements.txt) á»Ÿ thÆ° má»¥c gá»‘c.

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies

```bash
cd F:\3.Laptrinh\EnglishforIT
pip install -r requirements.txt
```

Packages cáº§n thiáº¿t (xem [requirements.txt](../../requirements.txt)):
- `langchain` + `langchain-community` + `langchain-huggingface`: Framework RAG
- `sentence-transformers`: Táº¡o embeddings
- `faiss-cpu`: Vector database
- `rank-bm25`: BM25 retrieval
- `numpy`: Xá»­ lÃ½ máº£ng

### BÆ°á»›c 2: Cháº¡y ingestion pipeline

```bash
cd F:\3.Laptrinh\EnglishforIT\step\2_ingestion
python ingestion_pipeline.py
```

Pipeline sáº½:
1. Load 4 JSON files tá»« `../../data/input/`
2. Táº¡o 212 LangChain Documents
3. Generate embeddings (384-dim vectors)
4. Build FAISS index
5. Save to `output/law_documents_index/`
6. Auto-test vá»›i query máº«u

**Thá»i gian cháº¡y**: ~30-60 giÃ¢y (CPU), ~10-15 giÃ¢y (GPU)

### BÆ°á»›c 3: Test retrieval

```bash
python demo_retrieval.py
```

Demo bao gá»“m:
- 5 test queries cÃ³ sáºµn
- Interactive mode Ä‘á»ƒ test query tÃ¹y Ã½
- Hiá»ƒn thá»‹ káº¿t quáº£ vá»›i score vÃ  metadata

### BÆ°á»›c 4: Load index trong code

```bash
python
```

Trong Python shell hoáº·c script:

```python
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cpu'}
)

vectorstore = FAISS.load_local(
    "output/law_documents_index",
    embeddings,
    allow_dangerous_deserialization=True
)

results = vectorstore.similarity_search("Quy Ä‘á»‹nh vá» báº£o vá»‡ Ä‘Ãª Ä‘iá»u", k=5)
```

## ğŸ”§ Chi tiáº¿t ká»¹ thuáº­t

### Embedding Model

**Model**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`

**ThÃ´ng sá»‘**:
- Vector dimension: 384
- Model size: ~471 MB (download láº§n Ä‘áº§u)
- Support: 50+ ngÃ´n ngá»¯ (bao gá»“m tiáº¿ng Viá»‡t)
- Tá»‘c Ä‘á»™: ~1000 docs/phÃºt (CPU), ~5000 docs/phÃºt (GPU)

**Æ¯u Ä‘iá»ƒm**:
- Lightweight nhÆ°ng accurate cho semantic search
- CÃ¢n báº±ng tá»‘t giá»¯a tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng
- Tá»‘i Æ°u cho multilingual content

**LÆ°u Ã½**: Láº§n cháº¡y Ä‘áº§u model sáº½ tá»± Ä‘á»™ng download tá»« HuggingFace (~471 MB)

### Document Structure

Má»—i LangChain Document bao gá»“m:

**page_content**: Ná»™i dung tá»« field `content_for_embedding` trong JSON

**metadata** (9 fields):
- `id`: Unique ID cho má»—i Ä‘iá»u (VD: "VBHN_05_2020_C1_D1")
- `doc_id`: ID vÄƒn báº£n (VD: "05/VBHN-VPQH")
- `doc_name`: TÃªn vÄƒn báº£n (VD: "VÄƒn báº£n há»£p nháº¥t Luáº­t ÄÃª Ä‘iá»u")
- `chapter_no`: Sá»‘ chÆ°Æ¡ng (VD: "I", "II")
- `chapter_name`: TÃªn chÆ°Æ¡ng
- `article_no`: Sá»‘ Ä‘iá»u (VD: "1", "2")
- `article_name`: TÃªn Ä‘iá»u
- `type`: Loáº¡i vÄƒn báº£n (VD: "phap_quy")
- `citation`: TrÃ­ch dáº«n Ä‘áº§y Ä‘á»§ (VD: "Äiá»u 1, Luáº­t ÄÃª Ä‘iá»u (VBHN 05/VBHN-VPQH)")

**ChÃº Ã½**: Metadata khá»›p 100% vá»›i JSON source, khÃ´ng thÃªm/bá»›t fields

### FAISS Configuration

**Index type**: IndexFlatL2 (exact nearest neighbor search)

**Äáº·c Ä‘iá»ƒm**:
- Similarity metric: L2 distance
- Exact search (khÃ´ng approximate)
- Tá»‘t cho dataset nhá»-trung (<1M vectors)
- Query time: <100ms

**Storage**:
- `index.faiss`: Binary FAISS index (325 KB)
- `index.pkl`: Docstore + metadata mapping (441 KB)

## ğŸ“Š Dá»¯ liá»‡u & Performance

### Input Data (data/input/)

| File | Records | Tá»· lá»‡ | Doc ID | Status |
|------|---------|-------|--------|--------|
| luatdedieu.json | 48 | 22.6% | VBHN_05_2020 | âœ… Clean |
| luatkhituongthuyvan.json | 57 | 26.9% | VBHN_06_2020 | âœ… Fixed (ID + citations) |
| luatphongchongthientai.json | 47 | 22.2% | VBHN_04_2020 | âœ… Clean |
| luatthuyloi.json | 60 | 28.3% | VBHN_05_2020 (khÃ¡c vá»›i ÄÃª Ä‘iá»u) | âœ… Clean |
| **TOTAL** | **212** | **100%** | | âœ… All unique IDs |

### Performance Metrics

| Metric | Value | Environment |
|--------|-------|-------------|
| Embedding time | ~30-60s | Intel CPU |
| Embedding time | ~10-15s | NVIDIA GPU |
| Index build time | <5s | Any |
| Index size | ~766 KB | 212 vectors |
| Vector dimension | 384 | Fixed |
| Query time | <100ms | Average |
| Memory usage | ~2 GB | Runtime |

### Validation Results

âœ… **Data Quality**: 100/100 score
- Táº¥t cáº£ 212 IDs unique (Ä‘Ã£ fix 20 duplicates)
- Citations chÃ­nh xÃ¡c 100% (Ä‘Ã£ fix 57 citations)
- Metadata structure khá»›p hoÃ n toÃ n vá»›i JSON
- KhÃ´ng cÃ³ missing/null values

âœ… **Search Quality**: Tested vá»›i query "Quy Ä‘á»‹nh vá» báº£o vá»‡ Ä‘Ãª Ä‘iá»u"
- Top results liÃªn quan chÃ­nh xÃ¡c
- Metadata Ä‘áº§y Ä‘á»§ vÃ  Ä‘Ãºng
- Citations trá» Ä‘Ãºng nguá»“n

## ğŸ“‹ Data Cleaning History

### Issues Ä‘Ã£ fix

1. **Duplicate IDs** (20 records):
   - Váº¥n Ä‘á»: luatkhituongthuyvan.json vÃ  luatthuyloi.json cÃ¹ng dÃ¹ng doc_id `VBHN_05_2020`
   - Fix: Äá»•i doc_id â†’ `VBHN_06_2020` cho luatkhituongthuyvan.json
   - File backup: `luatkhituongthuyvan.json.backup`

2. **Wrong Citations** (57 records):
   - Váº¥n Ä‘á»: Citations trong luatkhituongthuyvan.json hiá»ƒn thá»‹ "Luáº­t Thá»§y lá»£i"
   - Fix: Sá»­a thÃ nh "Luáº­t KhÃ­ tÆ°á»£ng thá»§y vÄƒn (VBHN 06/VBHN-VPQH)"
   - Script: `fix_citations.py` (Ä‘Ã£ xÃ³a sau khi hoÃ n thÃ nh)

3. **Metadata Structure**:
   - Váº¥n Ä‘á»: Code ban Ä‘áº§u thÃªm field `clause_no: None` khÃ´ng cÃ³ trong JSON
   - Fix: Remove field khá»i metadata creation logic

## âš™ï¸ Configuration Options

### TÃ¹y chá»‰nh trong ingestion_pipeline.py

```python
# Embedding device
EMBEDDING_DEVICE = "cpu"  # Äá»•i thÃ nh "cuda" náº¿u cÃ³ GPU

# Batch size
BATCH_SIZE = 32  # TÄƒng náº¿u cÃ³ RAM nhiá»u

# Model
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
```

### Alternative Models

CÃ³ thá»ƒ thay Ä‘á»•i model tÃ¹y má»¥c Ä‘Ã­ch:

**Tá»‘i Æ°u tiáº¿ng Viá»‡t**:
- `keepitreal/vietnamese-sbert`
- `VoVanPhuc/sup-SimCSE-VietNamese-phobert-base`

**Cháº¥t lÆ°á»£ng cao hÆ¡n** (trade-off: cháº­m hÆ¡n, náº·ng hÆ¡n):
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (768-dim)

**Nhanh hÆ¡n** (trade-off: kÃ©m accurate hÆ¡n):
- `sentence-transformers/paraphrase-multilingual-MiniLM-L6-v2` (384-dim, nháº¹ hÆ¡n)

## ğŸ”„ Workflow Integration

### Input (tá»« Giai Ä‘oáº¡n 1)
- Äá»c tá»«: `../../data/input/*.json`
- Format: Cleaned JSON vá»›i fields chuáº©n
- Validation: ÄÃ£ qua data cleaning pipeline

### Output (cho Giai Ä‘oáº¡n 3)
- FAISS index táº¡i: `output/law_documents_index/`
- Load method: `FAISS.load_local()`
- Usage: Retrieval trong RAG pipeline

### Next Steps (Giai Ä‘oáº¡n 3 - RAG)
1. Load FAISS index
2. Integrate vá»›i LLM (GPT/Claude/Gemini)
3. Implement retrieval + generation
4. Add citation tracking
5. Build chatbot interface

## âš ï¸ LÆ°u Ã½ quan trá»ng

### Láº§n cháº¡y Ä‘áº§u tiÃªn
- Model tá»± Ä‘á»™ng download (~471 MB)
- Cáº§n káº¿t ná»‘i internet
- Thá»i gian: ~5-10 phÃºt (tÃ¹y tá»‘c Ä‘á»™ máº¡ng)
- Cache táº¡i: `~/.cache/huggingface/`

### System Requirements
- RAM: â‰¥ 2 GB kháº£ dá»¥ng
- Disk: ~1 GB (model + index)
- CPU: Báº¥t ká»³ (khuyáº¿n nghá»‹ multi-core)
- GPU: Optional (tÄƒng tá»‘c ~5-10x)

### Security Warning
- File `index.pkl` chá»©a pickled objects
- Cáº§n `allow_dangerous_deserialization=True` khi load
- Chá»‰ load index tá»« nguá»“n tin cáº­y

### Troubleshooting

**Lá»—i import**: CÃ i láº¡i packages
```bash
pip install --upgrade langchain langchain-community langchain-huggingface
```

**Out of memory**: Giáº£m BATCH_SIZE hoáº·c dÃ¹ng CPU
```python
EMBEDDING_DEVICE = "cpu"
BATCH_SIZE = 16
```

**Model download cháº­m**: DÃ¹ng mirror HuggingFace hoáº·c download manual

## ğŸ“ˆ Scalability

### Hiá»‡n táº¡i (212 docs)
- Index type: IndexFlatL2 (exact search)
- Query time: <100ms
- PhÃ¹ há»£p vá»›i dataset size hiá»‡n táº¡i

### Má»Ÿ rá»™ng (>10K docs)
- Chuyá»ƒn sang IndexIVFFlat (approximate search)
- Sá»­ dá»¥ng GPU cho faster embedding
- Implement batch processing
- Consider distributed FAISS

### Production Deployment
- Cache embeddings Ä‘á»ƒ trÃ¡nh re-compute
- Monitor query latency
- Set up index versioning
- Implement incremental updates

## ğŸ“š TÃ i liá»‡u tham kháº£o

- **LangChain**: https://python.langchain.com/docs/integrations/vectorstores/faiss
- **FAISS**: https://faiss.ai/
- **Sentence Transformers**: https://www.sbert.net/
- **HuggingFace Models**: https://huggingface.co/sentence-transformers

---

**Status**: âœ… Production Ready  
**Last Updated**: 2026-01-31  
**Version**: 2.0  
**Data Quality**: 100/100  
**Total Vectors**: 212
