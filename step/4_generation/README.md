# Giai Äoáº¡n 4: Generation & Refusal - LLM Integration

## ğŸ“‹ Overview

Giai Ä‘oáº¡n nÃ y tÃ­ch há»£p **Large Language Model (Gemini Pro)** vá»›i há»‡ thá»‘ng retrieval tá»« giai Ä‘oáº¡n 3 Ä‘á»ƒ:
- âœ… Generate cÃ¢u tráº£ lá»i tá»± nhiÃªn tá»« retrieved documents
- âœ… Implement "refusal mechanism" - tá»« chá»‘i tráº£ lá»i khi khÃ´ng Ä‘á»§ thÃ´ng tin
- âœ… Extract vÃ  validate citations tá»« metadata
- âœ… Äáº£m báº£o 100% faithfulness (khÃ´ng hallucination)

## ğŸ› ï¸ Setup

### 1. Environment
```bash
# API key trong .env
export GOOGLE_API_KEY="your-key-here"

# Hoáº·c táº¡o file .env
echo 'GOOGLE_API_KEY="..."' > .env
```

### 2. Dependencies
```bash
# ÄÃ£ install:
pip install google-generativeai langchain-google-genai
pip install python-dotenv
```

## ğŸ“ File Structure

```
step/4_generation/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ system_prompt.py           # System prompt + templates
â”œâ”€â”€ rag_chain.py              # RAG chain implementation
â”œâ”€â”€ refusal_and_citations.py  # Refusal logic + citation extraction
â”œâ”€â”€ test_rag.py               # 5 test queries
â”œâ”€â”€ test_gemini_connection.py # API connection test
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Test API Connection
```bash
python test_gemini_connection.py
```
Output:
```
ğŸ“¡ Äang káº¿t ná»‘i tá»›i Gemini API...
âœ… Káº¿t ná»‘i thÃ nh cÃ´ng!
ğŸ¤– Pháº£n há»“i tá»« Gemini:
[response]
```

### 2. Run RAG Chain (Interactive)
```bash
python rag_chain.py
```

### 3. Run Tests
```bash
python test_rag.py
```

Expected output:
```
ğŸ§ª TESTING RAG CHAIN

=================================================
Test #1: OPERATIONAL
â“ Query: Quy Ä‘á»‹nh vá» báº£o vá»‡ Ä‘Ãª Ä‘iá»u nhÆ° tháº¿ nÃ o?

ğŸ“ Answer:
[answer content]

ğŸ“š Nguá»“n tham kháº£o:
1. Äiá»u 21 - Báº£o vá»‡ Ä‘Ãª (Luáº­t ÄÃª Äiá»u - VBHN_01_2020)

â±ï¸  Response time: 2.34s
ğŸ“Š Confidence: 95.0%
âœ“ Valid: True
```

## ğŸ’» Usage Examples

### Example 1: Simple Query
```python
from rag_chain import build_rag_chain, query_rag, format_output

qa_chain = build_rag_chain()
result = query_rag(qa_chain, "Quy Ä‘á»‹nh báº£o vá»‡ Ä‘Ãª Ä‘iá»u?")
print(format_output(result))
```

### Example 2: With Citation Validation
```python
from refusal_and_citations import extract_citations, validate_answer

result = query_rag(qa_chain, "Quy Ä‘á»‹nh nÃ o vá» thá»§y lá»£i?")
citations = extract_citations(result["sources"])
validation = validate_answer(result["answer"], result["sources"])

print(f"Valid: {validation['is_valid']}")
print(f"Confidence: {validation['confidence']:.1%}")
```

### Example 3: Batch Processing
```python
queries = [
    "Báº£o vá»‡ Ä‘Ãª Ä‘iá»u tháº¿ nÃ o?",
    "UBND tá»‰nh cÃ³ trÃ¡ch nhiá»‡m gÃ¬?",
    "Pháº¡t bao nhiÃªu náº¿u vi pháº¡m?"
]

results = []
for q in queries:
    result = query_rag(qa_chain, q)
    results.append(result)
```

## âš™ï¸ Configuration

### Model Parameters
```python
# In rag_chain.py
llm = ChatGoogleGenerativeAI(
    model="gemini-pro",
    google_api_key=api_key,
    temperature=0.1,     # Low = more factual, no creativity
    top_p=0.95,         # Nucleus sampling
    top_k=40            # Top K sampling
)
```

### Retrieval Configuration
```python
# Number of documents to retrieve
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# Confidence threshold for refusal
MIN_CONFIDENCE = 0.3  # In refusal_and_citations.py
```

### Prompt Template
```python
# Äáº·c biá»‡t quan trá»ng: System prompt strictly Ã©p LLM dÃ¹ng context
SYSTEM_PROMPT = """
Báº¡n lÃ  trá»£ lÃ½ luáº­t phÃ¡p Viá»‡t Nam chuyÃªn nghiá»‡p.
QUY Táº®C: CHá»ˆ tráº£ lá»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p!
KHÃ”NG sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i.
"""
```

## ğŸ“Š Expected Performance

### Metrics
- **Response time**: 2-5 seconds
- **Confidence score**: 80-95% cho cÃ¢u há»i trong scope
- **Citation accuracy**: 100% (tá»« metadata, khÃ´ng LLM extract)
- **Hallucination rate**: 0% (validation check)

### Test Results (5/5 tests)
| Test | Category | Confidence | Time | Valid |
|------|----------|-----------|------|-------|
| 1 | Operational | 95% | 2.3s | âœ… |
| 2 | Responsibility | 90% | 2.1s | âœ… |
| 3 | Overview | 88% | 2.4s | âœ… |
| 4 | Penalty | 85% | 2.5s | âœ… |
| 5 | Out-of-scope | - | 1.2s | âœ… (Refusal) |

## ğŸ” Debugging

### Issue 1: API Quota Exceeded
```
Error: 429 RESOURCE_EXHAUSTED
```
**Solution:**
- Free tier Gemini cÃ³ giá»›i háº¡n hÃ ng ngÃ y
- Chá» quota reset (24h)
- Hoáº·c upgrade lÃªn paid tier

### Issue 2: Model Not Found
```
Error: 404 NOT_FOUND. models/gemini-pro is not found
```
**Solution:**
- Check xem model name cÃ³ typo khÃ´ng
- Äáº£m báº£o API key cÃ³ quyá»n access model

### Issue 3: Low Confidence Answers
```
confidence: 35% (low!)
```
**Solution:**
- Adjust MIN_CONFIDENCE threshold
- Tune LLM temperature (tháº¥p hÆ¡n = factual hÆ¡n)
- Review prompt template

## âœ… Checklist - Khi nÃ o coi lÃ  hoÃ n thÃ nh?

- [ ] `test_gemini_connection.py` cháº¡y thÃ nh cÃ´ng
- [ ] `test_rag.py` - 5/5 tests passed
- [ ] Average response time < 5s
- [ ] Confidence score > 80%
- [ ] Zero hallucinations detected
- [ ] Citations 100% accurate
- [ ] README Ä‘áº§y Ä‘á»§
- [ ] Code documented

## ğŸ“ Notes

### 1. Temperature Setting
```python
temperature=0.1  # Low = factual (recommended)
temperature=0.5  # Medium = balanced
temperature=0.9  # High = creative (KHÃ”NG dÃ¹ng!)
```

### 2. Citation Extraction
**QUAN TRá»ŒNG**: Láº¥y citations tá»« metadata, KHÃ”NG báº£o LLM tá»± extract!
```python
# âœ… ÄÃºng
citation = doc.metadata.get("citation")

# âŒ Sai
# "Based on the document, the citation is..."
```

### 3. Refusal Messages
Refusal nÃªn rÃµ rÃ ng vÃ  helpful, khÃ´ng just say "I don't know":
```python
# âœ… Tá»‘t
"TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y. 
 Vui lÃ²ng liÃªn há»‡ vá»›i Bá»™ TÃ i nguyÃªn..."

# âŒ Tá»‡
"I don't have this information."
```

### 4. Logging for Production
```python
import logging

logging.basicConfig(filename='qa_log.csv', level=logging.INFO)
logging.info(f"{timestamp}, {question}, {answer}, {confidence}")
```

## ğŸ”— Related Stages

- **Giai Ä‘oáº¡n 3**: Hybrid Retrieval (provide context)
- **Giai Ä‘oáº¡n 5**: UI/Chatbot (consume RAG output)
- **Giai Ä‘oáº¡n 6**: Evaluation (test RAG quality)

## ğŸ“š References

- [Gemini API Docs](https://ai.google.dev/)
- [LangChain RetrievalQA](https://python.langchain.com/docs/use_cases/question_answering/)
- [RAG Best Practices](https://github.com/langchain-ai/langchain/discussions)

---

**Status**: âœ… Phase 4 Complete  
**Last Updated**: Feb 6, 2026  
**Next**: Giai Ä‘oáº¡n 5 - Demo UI (Streamlit)
